{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "import statistics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 9)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = pd.read_csv(\"test_data/test_data_0406.csv\")\n",
    "data = pd.read_csv(\"test_data/test_data.csv\")\n",
    "data['ratio'] = data['set'].apply(lambda x: x.split('_')[3])\n",
    "data['schedule_size'] = data['set'].apply(lambda x: x.split('_')[1])\n",
    "\n",
    "data.reward = data.reward.round(6)\n",
    "data['acceptable']= [1 if i == 1 else 0 for i in data['reward']]\n",
    "\n",
    "conditions = [\n",
    "            data['schedule_size'] =='easy',\n",
    "            data['schedule_size']=='medium',\n",
    "            data['schedule_size']=='hard',\n",
    "            data['schedule_size']=='extrahard',\n",
    "            data['schedule_size']=='xxhard',\n",
    "        ]\n",
    "\n",
    "outputs = ['ms8','ms14','ms18','ms23','ms30']\n",
    "X = np.select(conditions, outputs, 'Other')\n",
    "data['Problem Complexity (max shifts)'] = X\n",
    "\n",
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>reward</th>\n",
       "      <th>model</th>\n",
       "      <th>seed</th>\n",
       "      <th>set</th>\n",
       "      <th>ratio</th>\n",
       "      <th>schedule_size</th>\n",
       "      <th>acceptable</th>\n",
       "      <th>Problem Complexity (max shifts)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>1.0</td>\n",
       "      <td>step_8</td>\n",
       "      <td>10</td>\n",
       "      <td>shifts_easy_ratio_mixed</td>\n",
       "      <td>mixed</td>\n",
       "      <td>easy</td>\n",
       "      <td>1</td>\n",
       "      <td>08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   problem  reward   model  seed                      set  ratio  \\\n",
       "0      101     1.0  step_8    10  shifts_easy_ratio_mixed  mixed   \n",
       "\n",
       "  schedule_size  acceptable Problem Complexity (max shifts)  \n",
       "0          easy           1                              08  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def welch_test(data1, data2, alpha=0.05, tail=2):\n",
    "    \"\"\"\n",
    "    Wraps around ttest_ind function of scipy, without assuming equal variances.\n",
    "    Params\n",
    "    ------\n",
    "    - data1 (ndarray of dim 1)\n",
    "    The performance measures of Algo1.\n",
    "    - data2 (ndarray of dim 1)\n",
    "    The performance measures of Algo2.\n",
    "    - alpha (float in ]0,1[)\n",
    "    The significance level used by the Welch's t-test.\n",
    "    - tail (1 or 2)\n",
    "    Perform a one tail or two tail test.\n",
    "    \"\"\"\n",
    "\n",
    "    assert tail==1 or tail==2, \"tail should be one or two, referring to the one-sided or two-sided t-test.\"\n",
    "    data1 = data1.squeeze()\n",
    "    data2 = data2.squeeze()\n",
    "    assert alpha <1 and alpha >0, \"alpha should be between 0 and 1\"\n",
    "\n",
    "    t, p = stats.ttest_ind(data1, data2, equal_var=False)\n",
    "\n",
    "    if tail==1:\n",
    "        alpha = 2*alpha\n",
    "    if p <= alpha:\n",
    "        if t<0:\n",
    "            print(\"Result of the Welch's t-test at level %02g: μ2>μ1, the test passed with p-value = %02g.\" %(alpha, p))\n",
    "            print(f'd2 (m={statistics.mean(data2)}, sd={statistics.stdev(data2)}), d2 (m={statistics.mean(data1)}, sd={statistics.mean(data1)}), {alpha}, {p}')\n",
    "            \n",
    "            return alpha, p\n",
    "        else:\n",
    "            print(\"Result of the Welch's t-test level %02g: μ1>μ2, the test passed with p-value = %02g.\" %(alpha, p))\n",
    "            print(f'd1 (m={statistics.mean(data1)}, sd={statistics.stdev(data1)}), d2 (m={statistics.mean(data2)}, sd={statistics.mean(data2)}), {alpha}, {p}')\n",
    "            \n",
    "            return alpha, p\n",
    "    else:\n",
    "        print(\"Results of the Welch's t-test level %02g: there is not enough evidence to prove any order relation between μ1 and μ2.\" % alpha)\n",
    "        return alpha, 0\n",
    "    \n",
    "    print(\"Welch's t-test done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reward comparison\n",
    "data[data['model']=='terminal_8']\n",
    "data[data['model']=='step_8']\n",
    "data[data['model']=='stepbonus_8']\n",
    "data[data['model']=='random_0']\n",
    "\n",
    "# schedule_size comparison\n",
    "ms8 = data['reward'][data['Problem Complexity (max shifts)']=='ms8'] \n",
    "ms14 = data['reward'][data['Problem Complexity (max shifts)']=='ms14']\n",
    "ms18 = data['reward'][data['Problem Complexity (max shifts)']=='ms18']\n",
    "ms23 = data['reward'][data['Problem Complexity (max shifts)']=='ms23']\n",
    "ms30 = data['reward'][data['Problem Complexity (max shifts)']=='ms30']\n",
    "\n",
    "# ratio comparison\n",
    "average_ratio = data['reward'][data['ratio']=='mixed'] \n",
    "high_ratio = data['reward'][data['ratio']=='above'] \n",
    "\n",
    "average_ratio_acceptable = data['acceptable'][data['ratio']=='mixed'] \n",
    "high_ratio_acceptable = data['acceptable'][data['ratio']=='above'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = average_ratio_acceptable.to_numpy()\n",
    "data2 = high_ratio_acceptable.to_numpy()\n",
    "data1 = average_ratio.to_numpy()\n",
    "data2 = high_ratio.to_numpy()\n",
    "data1 = data['reward'][data['model']=='stepbonus_8'].to_numpy()\n",
    "data2 = data['reward'][data['model']=='random_0'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "\n",
    "combs = [(i,j) for i, j in combinations(data['model'].unique().tolist(), 2)]\n",
    "\n",
    "terminal_8 = data['reward'][data['model']=='terminal_8'].to_numpy()\n",
    "step_8 = data['reward'][data['model']=='step_8'].to_numpy()\n",
    "stepbonus_8 = data['reward'][data['model']=='stepbonus_8'].to_numpy()\n",
    "random_0 = data['reward'][data['model']=='random_0'].to_numpy()\n",
    "\n",
    "for i in combs:\n",
    "    print(i)\n",
    "    welch_test(eval(i[0]),eval(i[1]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of the Welch's t-test level 0.05: μ1>μ2, the test passed with p-value = 5.71597e-120.\n",
      "d1 (m=0.9591988016, sd=0.14820917206815876), d2 (m=0.8140200936, sd=0.8140200936)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.715967001040617e-120"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ratio\n",
    "\n",
    "combs = [(i,j) for i, j in combinations(data['ratio'].unique().tolist(), 2)]\n",
    "\n",
    "average_ratio = data['reward'][(data['ratio']=='mixed') & (data['model']!='random_0') & (data['model']=='stepbonus_8')].to_numpy()\n",
    "high_ratio = data['reward'][(data['ratio']=='above') & (data['model']!='random_0') & (data['model']=='stepbonus_8')].to_numpy()\n",
    "\n",
    "welch_test(average_ratio,high_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max shifts\n",
    "\n",
    "mdata = data[data['model']!='random_0']\n",
    "\n",
    "combs = [(i,j) for i, j in combinations(data['Problem Complexity (max shifts)'].unique().tolist(), 2)]\n",
    "\n",
    "\n",
    "ms8 = mdata['reward'][mdata['Problem Complexity (max shifts)']=='ms8'] \n",
    "ms14 = mdata['reward'][mdata['Problem Complexity (max shifts)']=='ms14']\n",
    "ms18 = mdata['reward'][mdata['Problem Complexity (max shifts)']=='ms18']\n",
    "ms23 = mdata['reward'][mdata['Problem Complexity (max shifts)']=='ms23']\n",
    "ms30 = mdata['reward'][mdata['Problem Complexity (max shifts)']=='ms30']\n",
    "\n",
    "for i in combs:\n",
    "    print(i)\n",
    "    welch_test(eval(i[0]),eval(i[1]))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mdata = data[(data['model']!='random_0') & (data['ratio']!='high')]\n",
    "\n",
    "combs = [(i,j) for i, j in combinations(data['Problem Complexity (max shifts)'].unique().tolist(), 2)]\n",
    "\n",
    "\n",
    "ms8 = mdata['reward'][mdata['Problem Complexity (max shifts)']=='ms8'] \n",
    "ms14 = mdata['reward'][mdata['Problem Complexity (max shifts)']=='ms14']\n",
    "ms18 = mdata['reward'][mdata['Problem Complexity (max shifts)']=='ms18']\n",
    "ms23 = mdata['reward'][mdata['Problem Complexity (max shifts)']=='ms23']\n",
    "ms30 = mdata['reward'][mdata['Problem Complexity (max shifts)']=='ms30']\n",
    "\n",
    "for i in combs:\n",
    "    print(i)\n",
    "    welch_test(eval(i[0]),eval(i[1]))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8710594505"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ndata = data[(data['model']=='stepbonus_8') & (data['Problem Complexity (max shifts)']!='ms30')  & (data['ratio']!='high')]\n",
    "\n",
    "\n",
    "ndata.reward.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.769499999999943"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(ndata.acceptable / len(ndata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of the Welch's t-test level 0.05: there is not enough evidence to prove any order relation between μ1 and μ2.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.05, 0)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mdata = data[data['model']=='stepbonus_8']\n",
    "\n",
    "ms8 = mdata['reward'][(mdata['Problem Complexity (max shifts)']=='ms8') & (mdata['ratio']=='average')] \n",
    "ms30 = mdata['reward'][(mdata['Problem Complexity (max shifts)']=='ms8') & (mdata['ratio']=='high')]\n",
    "\n",
    "welch_test(ms8,ms30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.2 64-bit ('rl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a5b0cbe14e1b88e411ba60f7f1e42d018a6caa56656953e7d806710a4690a6c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
